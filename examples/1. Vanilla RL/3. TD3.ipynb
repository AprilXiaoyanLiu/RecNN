{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import logging\n",
    "l = logging.getLogger()\n",
    "l.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import gc\n",
    "import json\n",
    "import h5py\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# comment out if you are not using themes\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='grade3')\n",
    "\n",
    "# == recnn ==\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import recnn\n",
    "\n",
    "cuda = torch.device('cuda')\n",
    "# ---\n",
    "frame_size = 10\n",
    "batch_size = 25\n",
    "# --- \n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# https://drive.google.com/open?id=1kTyu05ZmtP2MA33J5hWdX8OyUYEDW4iI\n",
    "movie_embeddings_key_dict = pickle.load(open('../../data/embeddings/ml20_pca128.pkl', 'rb'))\n",
    "# movie_embeddings_key_dict = pickle.load(open('../../data/embeddings/infos_pca128.pytorch', 'rb'))\n",
    "movies_embeddings_tensor, \\\n",
    "key_to_id, id_to_key = recnn.data.make_items_tensor(movie_embeddings_key_dict)\n",
    "# download ml20m dataset yourself\n",
    "ratings = pd.read_csv('../../data/ml-20m/ratings.csv')\n",
    "user_dict, users = recnn.data.prepare_dataset(ratings, key_to_id, frame_size)\n",
    "del ratings\n",
    "gc.collect()\n",
    "clear_output(True)\n",
    "clear_output(True)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"aa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def soft_update(net, target_net, soft_tau=1e-2):\n",
    "    for target_param, param in zip(target_net.parameters(), net.parameters()):\n",
    "            target_param.data.copy_(\n",
    "                target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "            )\n",
    "            \n",
    "def run_tests():\n",
    "    test_batch = next(iter(test_dataloader))\n",
    "    losses = td3_update(step, test_batch, params, learn=False)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def td3_update(step, batch, params, learn=True):\n",
    "    \n",
    "    batch = [i.to(cuda) for i in batch]\n",
    "    state, action, reward, next_state, done = batch\n",
    "    \n",
    "    # --------------------------------------------------------#\n",
    "    # Value Learning\n",
    "    \n",
    "    reward     = reward.unsqueeze(1)\n",
    "    done       = done.unsqueeze(1)\n",
    "    \n",
    "    next_action = target_policy_net(next_state)\n",
    "    noise = torch.normal(torch.zeros(next_action.size()),\n",
    "                         params['noise_std']).to(cuda)\n",
    "    noise = torch.clamp(noise, -params['noise_clip'], params['noise_clip'])\n",
    "    next_action += noise\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        target_q_value1  = target_value_net1(next_state, next_action)\n",
    "        target_q_value2  = target_value_net2(next_state, next_action)\n",
    "        target_q_value   = torch.min(target_q_value1, target_q_value2)\n",
    "        expected_q_value = reward + (1.0 - done) * params['gamma'] * target_q_value\n",
    "    \n",
    "    q_value1 = value_net1(state, action)\n",
    "    q_value2 = value_net2(state, action)\n",
    "\n",
    "    value_loss1 = value_criterion(q_value1, expected_q_value.detach())\n",
    "    value_loss2 = value_criterion(q_value2, expected_q_value.detach())\n",
    "    \n",
    "    debugger.log_error('value1', q_value1)\n",
    "    debugger.log_error('value2', q_value2)\n",
    "    debugger.log_error('next_action', next_action)\n",
    "    debugger.log_error('target_value ', target_q_value)\n",
    "    \n",
    "    if learn:\n",
    "        value_optimizer1.zero_grad()\n",
    "        value_loss1.backward()\n",
    "        value_optimizer1.step()\n",
    "\n",
    "        value_optimizer2.zero_grad()\n",
    "        value_loss2.backward()\n",
    "        value_optimizer2.step()\n",
    "    else:\n",
    "        writer.add_figure('next_action',\n",
    "                    recnn.plot.pairwise_distances_fig(next_action[:50]), step)\n",
    "        writer.add_histogram('value1', q_value1, step)\n",
    "        writer.add_histogram('value2', q_value2, step)\n",
    "        writer.add_histogram('target_value', target_q_value, step)\n",
    "        writer.add_histogram('expected_value', expected_q_value, step)\n",
    "\n",
    "    # --------------------------------------------------------#\n",
    "    # Policy learning\n",
    "\n",
    "    gen_action = policy_net(state)\n",
    "    policy_loss = value_net1(state, gen_action)\n",
    "    policy_loss = -policy_loss\n",
    "    \n",
    "    if learn:\n",
    "        debugger.log_object('gen_action', gen_action,  \"mat\")\n",
    "        \n",
    "    else: \n",
    "        debugger.log_object('test gen_action', gen_action, \"mat\")\n",
    "        writer.add_figure('gen_action',\n",
    "                    recnn.plot.pairwise_distances_fig(gen_action[:50]), step)\n",
    "        writer.add_histogram('policy_loss', policy_loss, step)\n",
    "        \n",
    "    policy_loss = policy_loss.mean()\n",
    "    \n",
    "    # delayed policy update\n",
    "    if step % params['policy_update'] == 0 and learn:\n",
    "        policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(policy_net.parameters(), -1, 1)\n",
    "        policy_optimizer.step()\n",
    "\n",
    "        soft_update(value_net1, target_value_net1, soft_tau=params['soft_tau'])\n",
    "        soft_update(value_net2, target_value_net2, soft_tau=params['soft_tau'])\n",
    "    \n",
    "    losses = {'value1': value_loss1.item(),\n",
    "              'value2': value_loss2.item(),\n",
    "              'policy': policy_loss.item(),\n",
    "              'step'  : step}\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# === TD3 settings ===\n",
    "params = {\n",
    "    'gamma': 0.99,\n",
    "    'noise_std': 0.1,\n",
    "    'noise_clip': 0.3,\n",
    "    'soft_tau': 0.001,\n",
    "    'policy_lr': 1e-5,\n",
    "    'value_lr': 1e-5,\n",
    "    'policy_update': 30,\n",
    "    'actor_weight_init': 3e-1,\n",
    "    'critic_weight_init': 6e-1,\n",
    "}\n",
    "# === end ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "value_net1  = recnn.models.Critic(1290, 128, 256, params['critic_weight_init']).to(cuda)\n",
    "value_net2 = recnn.models.Critic(1290, 128, 256, params['critic_weight_init']).to(cuda)\n",
    "policy_net = recnn.models.Actor(1290, 128, 256, params['actor_weight_init']).to(cuda)\n",
    "\n",
    "target_value_net1 = recnn.models.Critic(1290, 128, 256).to(cuda)\n",
    "target_value_net2 = recnn.models.Critic(1290, 128, 256).to(cuda)\n",
    "target_policy_net = recnn.models.Actor(1290, 128, 256).to(cuda)\n",
    "\n",
    "nets =[value_net1, value_net2, policy_net]\n",
    "\n",
    "soft_update(value_net1, target_value_net1, soft_tau=1.0)\n",
    "soft_update(value_net2, target_value_net2, soft_tau=1.0)\n",
    "soft_update(policy_net, target_policy_net, soft_tau=1.0)\n",
    "\n",
    "\n",
    "value_criterion = nn.MSELoss()\n",
    "\n",
    "value_optimizer1 = optim.Adam(value_net1.parameters(), lr=params['value_lr'])\n",
    "value_optimizer2 = optim.Adam(value_net2.parameters(), lr=params['value_lr'])\n",
    "policy_optimizer = optim.Adam(policy_net.parameters(), lr=params['policy_lr'])\n",
    "\n",
    "\n",
    "layout = {\n",
    "    'train': {'value1': [], 'value2': [], 'policy': [], 'step': []},\n",
    "    'test': {'value1': [], 'value2': [], 'policy': [], 'step': []}\n",
    "    }\n",
    "\n",
    "writer = SummaryWriter(log_dir='../../runs')\n",
    "debugger = recnn.Debugger(layout, run_tests, writer)\n",
    "plotter = recnn.Plotter(debugger, [['value1', 'policy']],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "step = 1\n",
    "n_epochs = 100\n",
    "batch_size = 25\n",
    "\n",
    "epoch_bar = tqdm(total=n_epochs)\n",
    "\n",
    "train_users = users[:-5000]\n",
    "test_users = users[-5000:]\n",
    "\n",
    "def prepare_batch_wrapper(x):\n",
    "    batch = recnn.data.prepare_batch_static_size(x, movies_embeddings_tensor, frame_size=frame_size)\n",
    "    return batch\n",
    "\n",
    "train_user_dataset = recnn.data.UserDataset(train_users, user_dict)\n",
    "test_user_dataset = recnn.data.UserDataset(test_users, user_dict)\n",
    "train_dataloader = DataLoader(train_user_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=1,collate_fn=prepare_batch_wrapper)\n",
    "test_dataloader = DataLoader(test_user_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=1,collate_fn=prepare_batch_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# --- config ---\n",
    "plot_every = 30\n",
    "# --- end ---\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_bar.update(1)\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        loss = td3_update(step, batch, params)\n",
    "        debugger.log_losses(loss)\n",
    "        step += 1\n",
    "        debugger.log_step(step)\n",
    "        if step % plot_every == 0:\n",
    "            clear_output(True)\n",
    "            print('step', step)\n",
    "            debugger.test()\n",
    "            plotter.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "l.critical('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#torch.save(value_net1.state_dict(), \"../../models/td3_value_1.pt\")\n",
    "#torch.save(policy_net.state_dict(), \"../../models/td3_policy_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "debugger.err_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "debugger.matshow('gen_action')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "debugger.matshow('test gen_action')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "gen_actions = debugger.debug_dict['mat']['gen_action']\n",
    "gen_test_actions = debugger.debug_dict['mat']['test gen_action']\n",
    "true_actions = np.stack(movie_embeddings_key_dict.values())\n",
    "    \n",
    "ad = recnn.models.AnomalyDetector().to(cuda)\n",
    "ad.load_state_dict(torch.load('../../models/anomaly.pt'))\n",
    "ad.eval()\n",
    "\n",
    "debugger.plot_kde_reconstruction_error(ad, gen_actions, gen_test_actions, true_actions, cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (RecNN)",
   "language": "python",
   "name": "pycharm-479d97fe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
