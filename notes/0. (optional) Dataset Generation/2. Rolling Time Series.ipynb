{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation\n",
    "You can do dynamic generation on the go, but it usually takes around 1.5 hours to go through the dataset. I prefer to use statically generated dataset because it allows to iterate throught the dataset in am matter of 4 minutes. Frame size in the number of actions you want to be in the state (the number of movies rated). I have chosen it to be 10, if you want another number you will have to generate it yourself. Link to the google drive is in the readme.md\n",
    "\n",
    "\n",
    "## This is a mandatory thing to do, you can download the existing dataset here: [Link](https://drive.google.com/open?id=1pPf-7AmUVceVfgfmKEJ6ireEDKEJHw-7)\n",
    "\n",
    "\n",
    "\n",
    "### Things you will need to download:\n",
    "- [Movie embeddings](https://drive.google.com/open?id=1kTyu05ZmtP2MA33J5hWdX8OyUYEDW4iI) or you can generate them yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Genaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "## Settings here!\n",
    "frame_size = 10\n",
    "batch_size = 1000\n",
    "## End settings\n",
    "\n",
    "csv_ratings = pd.read_csv('../../data/ml-20m/ratings.csv')\n",
    "ratings = h5py.File(\"../../data/test/test.hdf5\", \"r\")\n",
    "\n",
    "# credits: KnightofK9\n",
    "users = csv_ratings.groupby([\"userId\"]).size()\n",
    "users = users[users >= frame_size + 1]\n",
    "\n",
    "del csv_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "h5 = h5py.File(\"../../data/test/test_rolling.hdf5\", \"w\")\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ratings = h5.create_dataset(\"ratings\", (0, 11), maxshape=(None, 256), dtype='int8', chunks=True, compression=\"lzf\")\n",
    "ds_movies = h5.create_dataset(\"movies\", (0, 11), maxshape=(None, 256), dtype='int32',  chunks=True, compression=\"lzf\")\n",
    "ds_done = h5.create_dataset(\"done\", (0, ), maxshape=(None,), dtype='?', chunks=True,  compression=\"lzf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568a58524eea4b66bcb615467b90b07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=138493), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-417e1ced7281>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mratings_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mdone_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mds_movies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mds_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mds_done\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdone_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;31m# Check for array dtype compatibility and convert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "user_bar = tqdm(total=len(users))\n",
    "batch = []\n",
    "\n",
    "g_idx = 0\n",
    "batch = []\n",
    "for user in users.index:\n",
    "    user_bar.update(1)\n",
    "    group = ratings['u' + str(user)]\n",
    "    movies = group['movies'][:]\n",
    "    rates = group['ratings'][:]\n",
    "    size = len(movies) - frame_size\n",
    "    for idx in range(0, size):\n",
    "        if np.random.rand() < 0.8:  # intake percents\n",
    "            continue\n",
    "        batch.append([movies[idx:frame_size + idx + 1],\n",
    "                      movies[idx:frame_size + idx + 1],\n",
    "                      idx + 1 == size])\n",
    "        if len(batch) % batch_size == 0:\n",
    "            \n",
    "            [i.resize([len(batch) + i.shape[0], i.shape[1]]) for i in [ds_ratings, ds_movies]]\n",
    "            [i.resize([len(batch) + i.shape[0]]) for i in [ds_done]]\n",
    "            \n",
    "            for i in batch:\n",
    "                movies_, ratings_, done_ = i\n",
    "\n",
    "                movies_ = np.array(movies_)\n",
    "                ratings_ = np.array(ratings_)\n",
    "                done_ = np.array(done_)\n",
    "                ds_movies[g_idx] = movies_.astype('int32')\n",
    "                ds_ratings[g_idx] = ratings_.astype('int8')\n",
    "                ds_done[g_idx] = done_.astype('?')\n",
    "                \n",
    "                g_idx+=1\n",
    "\n",
    "            batch = []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "movie_ref = pickle.load(open('../data/infos_pca128.pytorch', 'rb'))\n",
    "\n",
    "f = h5py.File(\"../../data/test/test_rolling.hdf5\", \"r\")\n",
    "\n",
    "cuda = torch.device('cuda')\n",
    "\n",
    "def prepare_batch(*args):\n",
    "    args = [torch.tensor(np.array(arg).astype(np.float)).to(cuda) for arg in args]\n",
    "    return args\n",
    "\n",
    "\n",
    "batch_size = 5000\n",
    "losses = []\n",
    "T_losses = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(f['done'].shape[0] // batch_size)):\n",
    "    movies, ratings, done = [f[key][i*batch_size:(i+1)*batch_size] for key in\n",
    "             ['movies', 'ratings', 'done']]\n",
    "    \n",
    "    movies, ratings, done = [torch.tensor(i.astype('float32')) for i in [movies, ratings, done]]\n",
    "    movies_tensor = torch.stack([torch.stack([movie_ref[int(i)] for i in ts]) for ts in movies])\n",
    "    \n",
    "    state = torch.cat([movies_tensor[:, :-1, :].view(state.size(0), -1),\n",
    "                       ratings[:, :-1]], 1)\n",
    "    next_state = torch.cat([movies_tensor[:, 1:, :].view(state.size(0), -1),\n",
    "                            ratings[:, 1:]], 1)\n",
    "    action = movies_tensor[:, -1]\n",
    "    reward = ratings[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
